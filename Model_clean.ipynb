{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-17T14:37:13.112944Z",
     "start_time": "2025-04-17T14:37:13.107443Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "execution_count": 158
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T14:37:48.811389Z",
     "start_time": "2025-04-17T14:37:48.721706Z"
    }
   },
   "cell_type": "code",
   "source": [
    "activity = pd.read_csv('data/features/activity.csv')\n",
    "performances = pd.read_csv('data/features/performances.csv')"
   ],
   "id": "c443fa3f4ee6995",
   "outputs": [],
   "execution_count": 167
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T14:37:48.995036Z",
     "start_time": "2025-04-17T14:37:48.982060Z"
    }
   },
   "cell_type": "code",
   "source": [
    "performances_math = performances[performances['domain']== 'math'].copy()\n",
    "activity_math = activity[activity['domain']== 'math'].copy()"
   ],
   "id": "cce5a47e82078486",
   "outputs": [],
   "execution_count": 168
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T14:37:49.396027Z",
     "start_time": "2025-04-17T14:37:49.381850Z"
    }
   },
   "cell_type": "code",
   "source": "activity_math.dropna(inplace=True)",
   "id": "7dc9f3e344a0bd4c",
   "outputs": [],
   "execution_count": 169
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T14:37:52.901887Z",
     "start_time": "2025-04-17T14:37:49.839532Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Rolling window for recent activity\n",
    "rolling_window_days = 10\n",
    "\n",
    "# Convert the 'date' columns to datetime\n",
    "activity_math['activity_updated'] = pd.to_datetime(activity_math['activity_updated'])\n",
    "performances_math['time'] = pd.to_datetime(performances_math['time'])\n",
    "\n",
    "def compute_all_features_for_exam(exam_row, user_activities, user_exams, window_days=rolling_window_days):\n",
    "\n",
    "    exam_dt = exam_row['time']\n",
    "\n",
    "    # Include activities up to and including exam_date\n",
    "    previous_activities = user_activities[user_activities['activity_updated'] < exam_dt].copy()\n",
    "\n",
    "    # Rolling window (activities in the last N days, including exam day)\n",
    "    window_start = exam_dt - pd.Timedelta(days=window_days)\n",
    "    rolling_activities = previous_activities[previous_activities['activity_updated'] >= window_start].copy()\n",
    "\n",
    "    features = {}\n",
    "\n",
    "    # Recent average time per activity (rolling window)\n",
    "    total_time_rolling = rolling_activities['time_in_minutes'].sum()\n",
    "    count_rolling = len(rolling_activities)\n",
    "    features['recent_avg_time_per_activity'] = total_time_rolling / count_rolling if count_rolling > 0 else 0\n",
    "\n",
    "    # Number of days since last activity\n",
    "    if not previous_activities.empty:\n",
    "        last_activity_date = previous_activities['activity_updated'].max()\n",
    "        features['days_since_last_activity'] = (exam_dt - last_activity_date).days\n",
    "    else:\n",
    "        features['days_since_last_activity'] = np.nan\n",
    "\n",
    "    # Total time spent on activities before the exam\n",
    "    features['total_time_spent_on_activity_before_exam'] = previous_activities['time_in_minutes'].sum() if not previous_activities.empty else 0\n",
    "\n",
    "    # Average percentage on past exams\n",
    "    previous_exams = user_exams[user_exams['time'] < exam_dt]\n",
    "    features['average_percentage_past_exams'] = previous_exams['percentage'].mean() if not previous_exams.empty else np.nan\n",
    "\n",
    "    # Usage Frequency: Average activities per day in rolling window & Active days ratio\n",
    "    features['avg_activities_per_day_recent'] = count_rolling / window_days if window_days > 0 else np.nan\n",
    "    if not rolling_activities.empty:\n",
    "        distinct_days = rolling_activities['activity_updated'].dt.normalize().nunique()\n",
    "    else:\n",
    "        distinct_days = 0\n",
    "    features['active_days_ratio_recent'] = distinct_days / window_days if window_days > 0 else np.nan\n",
    "\n",
    "    # Activity diversity (rolling window)\n",
    "    features['diversity_recent'] = rolling_activities['activity_type'].nunique() if not rolling_activities.empty else 0\n",
    "\n",
    "\n",
    "    return pd.Series(features)\n",
    "\n",
    "# Loop over each exam (grouped by user) in performances_math and compute all features.\n",
    "features_list = []\n",
    "\n",
    "for user_id, user_exams in performances_math.groupby('user_id'):\n",
    "    # Get corresponding activities for the user from activity_math and sort by date\n",
    "    user_activities = activity_math[activity_math['user_id'] == user_id].sort_values('activity_updated')\n",
    "    user_exams_sorted = user_exams.sort_values('time')\n",
    "\n",
    "    for exam_index, exam_row in user_exams_sorted.iterrows():\n",
    "        feats = compute_all_features_for_exam(exam_row, user_activities, user_exams_sorted, rolling_window_days)\n",
    "        feats['exam_index'] = exam_index\n",
    "        features_list.append(feats)\n",
    "\n",
    "# Output df\n",
    "features_df = pd.DataFrame(features_list).set_index('exam_index')\n",
    "performances_math_features = performances_math.join(features_df, how='left')"
   ],
   "id": "9534bd1f49b2ca85",
   "outputs": [],
   "execution_count": 170
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T14:37:17.865045Z",
     "start_time": "2025-04-17T14:37:17.861574Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# do not run actually makes the model worst\n",
    "'''\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# 1) Define which features we’ll use to compute “similarity”:\n",
    "sim_features = [\n",
    "    'recent_avg_time_per_activity',\n",
    "    'days_since_last_activity',\n",
    "    'total_time_spent_on_activity_before_exam',\n",
    "    'avg_activities_per_day_recent',\n",
    "    'active_days_ratio_recent',\n",
    "    'diversity_recent'\n",
    "]\n",
    "\n",
    "# 2) Prepare a column to hold the imputed values\n",
    "performances_math_features['avg_pct_past_exams_imputed'] = performances_math_features['average_percentage_past_exams']\n",
    "\n",
    "# 3) Group by test_id and run kNN inside each group\n",
    "for test_id, group in performances_math_features.groupby('test_id'):\n",
    "    # indices of rows we need to fill\n",
    "    missing_idx = group[group['average_percentage_past_exams'].isna()].index\n",
    "    if len(missing_idx) == 0:\n",
    "        continue\n",
    "\n",
    "    # candidate neighbors: same test, non‐missing avg_pct\n",
    "    candidates = group[group['average_percentage_past_exams'].notna()]\n",
    "    if candidates.shape[0] == 0:\n",
    "        # no one else took that test (we can skip or fill global median)\n",
    "        continue\n",
    "\n",
    "    # Build a little matrix of sim_features, median‐imputed for any remaining NaNs\n",
    "    feat_mat = group[sim_features].copy()\n",
    "    feat_mat = feat_mat.fillna(feat_mat.median())\n",
    "\n",
    "    # Split into X_train (candidates) and X_query (the missing rows)\n",
    "    X_train = feat_mat.loc[candidates.index].values\n",
    "    X_query = feat_mat.loc[missing_idx].values\n",
    "\n",
    "    # We’ll use up to 3 neighbors (fewer if not enough candidates)\n",
    "    k = min(3, X_train.shape[0])\n",
    "    nbrs = NearestNeighbors(n_neighbors=k, algorithm='auto').fit(X_train)\n",
    "    distances, neighbors = nbrs.kneighbors(X_query)\n",
    "\n",
    "    # For each missing row, average the **actual test scores** of its neighbors\n",
    "    candidate_scores = candidates['percentage'].values  # their score on that same test\n",
    "    for i, idx in enumerate(missing_idx):\n",
    "        nbr_idxs = neighbors[i]                   # e.g. array([5, 12,  3])\n",
    "        imputed_val = candidate_scores[nbr_idxs].mean()\n",
    "        performances_math_features.at[idx, 'avg_pct_past_exams_imputed'] = imputed_val\n",
    "\n",
    "# 4) Replace the original column (or keep both)\n",
    "performances_math_features['average_percentage_past_exams'] = performances_math_features['avg_pct_past_exams_imputed']\n",
    "performances_math_features.drop(columns='avg_pct_past_exams_imputed', inplace=True)\n",
    "'''"
   ],
   "id": "3fb49300c270f086",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom sklearn.neighbors import NearestNeighbors\\n\\n# 1) Define which features we’ll use to compute “similarity”:\\nsim_features = [\\n    'recent_avg_time_per_activity',\\n    'days_since_last_activity',\\n    'total_time_spent_on_activity_before_exam',\\n    'avg_activities_per_day_recent',\\n    'active_days_ratio_recent',\\n    'diversity_recent'\\n]\\n\\n# 2) Prepare a column to hold the imputed values\\nperformances_math_features['avg_pct_past_exams_imputed'] = performances_math_features['average_percentage_past_exams']\\n\\n# 3) Group by test_id and run kNN inside each group\\nfor test_id, group in performances_math_features.groupby('test_id'):\\n    # indices of rows we need to fill\\n    missing_idx = group[group['average_percentage_past_exams'].isna()].index\\n    if len(missing_idx) == 0:\\n        continue\\n\\n    # candidate neighbors: same test, non‐missing avg_pct\\n    candidates = group[group['average_percentage_past_exams'].notna()]\\n    if candidates.shape[0] == 0:\\n        # no one else took that test (we can skip or fill global median)\\n        continue\\n\\n    # Build a little matrix of sim_features, median‐imputed for any remaining NaNs\\n    feat_mat = group[sim_features].copy()\\n    feat_mat = feat_mat.fillna(feat_mat.median())\\n\\n    # Split into X_train (candidates) and X_query (the missing rows)\\n    X_train = feat_mat.loc[candidates.index].values\\n    X_query = feat_mat.loc[missing_idx].values\\n\\n    # We’ll use up to 3 neighbors (fewer if not enough candidates)\\n    k = min(3, X_train.shape[0])\\n    nbrs = NearestNeighbors(n_neighbors=k, algorithm='auto').fit(X_train)\\n    distances, neighbors = nbrs.kneighbors(X_query)\\n\\n    # For each missing row, average the **actual test scores** of its neighbors\\n    candidate_scores = candidates['percentage'].values  # their score on that same test\\n    for i, idx in enumerate(missing_idx):\\n        nbr_idxs = neighbors[i]                   # e.g. array([5, 12,  3])\\n        imputed_val = candidate_scores[nbr_idxs].mean()\\n        performances_math_features.at[idx, 'avg_pct_past_exams_imputed'] = imputed_val\\n\\n# 4) Replace the original column (or keep both)\\nperformances_math_features['average_percentage_past_exams'] = performances_math_features['avg_pct_past_exams_imputed']\\nperformances_math_features.drop(columns='avg_pct_past_exams_imputed', inplace=True)\\n\""
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 163
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "imputing the values for the average percantage past exams actually make the model worst --> will just drop the rows",
   "id": "e01615e2845530fa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T14:38:05.278792Z",
     "start_time": "2025-04-17T14:38:05.269402Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# scaling the columns\n",
    "columns_to_scale = ['recent_avg_time_per_activity', 'days_since_last_activity', 'total_time_spent_on_activity_before_exam','average_percentage_past_exams','avg_activities_per_day_recent','active_days_ratio_recent','diversity_recent']\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_values = scaler.fit_transform(performances_math_features[columns_to_scale])\n",
    "scaled_df = pd.DataFrame(scaled_values, columns=columns_to_scale, index=performances_math_features.index)\n",
    "remaining_df = performances_math_features.drop(columns=columns_to_scale)\n",
    "final_df = pd.concat([scaled_df, remaining_df], axis=1)"
   ],
   "id": "81b3e5c5e5118ce0",
   "outputs": [],
   "execution_count": 171
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T14:38:05.989471Z",
     "start_time": "2025-04-17T14:38:05.983421Z"
    }
   },
   "cell_type": "code",
   "source": "final_df.dropna(inplace=True)",
   "id": "4eee2dd03a107793",
   "outputs": [],
   "execution_count": 172
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T14:38:07.270504Z",
     "start_time": "2025-04-17T14:38:07.249103Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# Linear Regression Model\n",
    "mod = smf.ols(formula= 'performance ~  recent_avg_time_per_activity + days_since_last_activity + total_time_spent_on_activity_before_exam + average_percentage_past_exams + avg_activities_per_day_recent + active_days_ratio_recent + diversity_recent', data=final_df)\n",
    "\n",
    "# Fit the model\n",
    "res = mod.fit()\n",
    "\n",
    "# Print regression results summary\n",
    "print(res.summary())"
   ],
   "id": "d33cc8a2d25a4e1f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:            performance   R-squared:                       0.237\n",
      "Model:                            OLS   Adj. R-squared:                  0.236\n",
      "Method:                 Least Squares   F-statistic:                     148.0\n",
      "Date:                Thu, 17 Apr 2025   Prob (F-statistic):          1.18e-190\n",
      "Time:                        16:38:07   Log-Likelihood:                -15488.\n",
      "No. Observations:                3340   AIC:                         3.099e+04\n",
      "Df Residuals:                    3332   BIC:                         3.104e+04\n",
      "Df Model:                           7                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "============================================================================================================\n",
      "                                               coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------------------------------\n",
      "Intercept                                    0.0012      0.437      0.003      0.998      -0.856       0.858\n",
      "recent_avg_time_per_activity                 2.3354      0.457      5.110      0.000       1.439       3.231\n",
      "days_since_last_activity                     1.2757      0.614      2.077      0.038       0.071       2.480\n",
      "total_time_spent_on_activity_before_exam     2.8336      0.457      6.202      0.000       1.938       3.729\n",
      "average_percentage_past_exams               11.3822      0.465     24.479      0.000      10.471      12.294\n",
      "avg_activities_per_day_recent               -2.2670      0.535     -4.235      0.000      -3.317      -1.217\n",
      "active_days_ratio_recent                     1.0794      0.591      1.825      0.068      -0.080       2.239\n",
      "diversity_recent                            -0.5710      0.653     -0.874      0.382      -1.852       0.710\n",
      "==============================================================================\n",
      "Omnibus:                       34.577   Durbin-Watson:                   1.586\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               24.298\n",
      "Skew:                          -0.089   Prob(JB):                     5.29e-06\n",
      "Kurtosis:                       2.622   Cond. No.                         2.83\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "execution_count": 173
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## test without the time dependant activity features",
   "id": "f02a27eb11e34336"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T14:39:25.537066Z",
     "start_time": "2025-04-17T14:39:25.430563Z"
    }
   },
   "cell_type": "code",
   "source": [
    "activity = pd.read_csv('data/features/activity.csv')\n",
    "performances = pd.read_csv('data/features/performances.csv')"
   ],
   "id": "6bbf526c7997d982",
   "outputs": [],
   "execution_count": 174
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T14:39:25.697200Z",
     "start_time": "2025-04-17T14:39:25.685235Z"
    }
   },
   "cell_type": "code",
   "source": [
    "performances_math = performances[performances['domain']== 'math'].copy()\n",
    "activity_math = activity[activity['domain']== 'math'].copy()"
   ],
   "id": "a60d4df5a0040816",
   "outputs": [],
   "execution_count": 175
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T14:39:25.999911Z",
     "start_time": "2025-04-17T14:39:25.988196Z"
    }
   },
   "cell_type": "code",
   "source": "activity_math",
   "id": "4888a3c1d9f2573a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       activity_id  user_id  post_id  course_id activity_type  \\\n",
       "0             1128     2533       42         42        course   \n",
       "1             1129     2533       55         42        lesson   \n",
       "2             1130     2533       98         42         topic   \n",
       "3             1131     2533      100         42         topic   \n",
       "4             1132     2533      102         42         topic   \n",
       "...            ...      ...      ...        ...           ...   \n",
       "50137       114742      955      647         42         topic   \n",
       "50138       114743      955      106         42         topic   \n",
       "50139       114744      955      104         42         topic   \n",
       "50140       114745      955      108         42         topic   \n",
       "50141       114746      955     2945         42          quiz   \n",
       "\n",
       "       activity_status     activity_started   activity_completed  \\\n",
       "0                    0  2023-04-07 16:42:35  2023-04-07 17:35:15   \n",
       "1                    0  2023-04-07 16:42:35                  NaN   \n",
       "2                    1  2023-04-07 16:42:38  2023-04-07 16:43:58   \n",
       "3                    1  2023-04-07 16:43:59  2023-04-07 16:46:13   \n",
       "4                    1  2023-04-07 16:46:14  2023-04-07 16:46:27   \n",
       "...                ...                  ...                  ...   \n",
       "50137                0  2025-03-07 06:36:32                  NaN   \n",
       "50138                0  2025-03-07 06:37:49                  NaN   \n",
       "50139                0  2025-03-07 06:37:50                  NaN   \n",
       "50140                0  2025-03-07 06:37:54                  NaN   \n",
       "50141                1  2025-03-07 06:42:09  2025-03-07 06:54:21   \n",
       "\n",
       "          activity_updated domain  date_restored  times_valid        date  \\\n",
       "0      2023-04-07 17:35:15   math           True         True  2023-04-07   \n",
       "1      2023-04-07 16:42:35   math          False         True  2023-04-07   \n",
       "2      2023-04-07 16:43:58   math          False         True  2023-04-07   \n",
       "3      2023-04-07 16:46:13   math          False         True  2023-04-07   \n",
       "4      2023-04-07 16:46:27   math          False         True  2023-04-07   \n",
       "...                    ...    ...            ...          ...         ...   \n",
       "50137  2025-03-07 06:36:32   math          False         True  2025-03-07   \n",
       "50138  2025-03-07 06:37:49   math          False         True  2025-03-07   \n",
       "50139  2025-03-07 06:37:50   math          False         True  2025-03-07   \n",
       "50140  2025-03-07 06:37:54   math          False         True  2025-03-07   \n",
       "50141  2025-03-07 06:54:21   math          False         True  2025-03-07   \n",
       "\n",
       "            time_spent  time_in_minutes  time_truncated  \n",
       "0      0 days 00:52:40        52.666667           False  \n",
       "1      0 days 00:00:00         0.000000           False  \n",
       "2      0 days 00:01:20         1.333333           False  \n",
       "3      0 days 00:02:14         2.233333           False  \n",
       "4      0 days 00:00:13         0.216667           False  \n",
       "...                ...              ...             ...  \n",
       "50137  0 days 00:00:00         0.000000           False  \n",
       "50138  0 days 00:00:00         0.000000           False  \n",
       "50139  0 days 00:00:00         0.000000           False  \n",
       "50140  0 days 00:00:00         0.000000           False  \n",
       "50141  0 days 00:12:12        12.200000           False  \n",
       "\n",
       "[25938 rows x 16 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activity_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>post_id</th>\n",
       "      <th>course_id</th>\n",
       "      <th>activity_type</th>\n",
       "      <th>activity_status</th>\n",
       "      <th>activity_started</th>\n",
       "      <th>activity_completed</th>\n",
       "      <th>activity_updated</th>\n",
       "      <th>domain</th>\n",
       "      <th>date_restored</th>\n",
       "      <th>times_valid</th>\n",
       "      <th>date</th>\n",
       "      <th>time_spent</th>\n",
       "      <th>time_in_minutes</th>\n",
       "      <th>time_truncated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1128</td>\n",
       "      <td>2533</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>course</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-04-07 16:42:35</td>\n",
       "      <td>2023-04-07 17:35:15</td>\n",
       "      <td>2023-04-07 17:35:15</td>\n",
       "      <td>math</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2023-04-07</td>\n",
       "      <td>0 days 00:52:40</td>\n",
       "      <td>52.666667</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1129</td>\n",
       "      <td>2533</td>\n",
       "      <td>55</td>\n",
       "      <td>42</td>\n",
       "      <td>lesson</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-04-07 16:42:35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-04-07 16:42:35</td>\n",
       "      <td>math</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2023-04-07</td>\n",
       "      <td>0 days 00:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1130</td>\n",
       "      <td>2533</td>\n",
       "      <td>98</td>\n",
       "      <td>42</td>\n",
       "      <td>topic</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-04-07 16:42:38</td>\n",
       "      <td>2023-04-07 16:43:58</td>\n",
       "      <td>2023-04-07 16:43:58</td>\n",
       "      <td>math</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2023-04-07</td>\n",
       "      <td>0 days 00:01:20</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1131</td>\n",
       "      <td>2533</td>\n",
       "      <td>100</td>\n",
       "      <td>42</td>\n",
       "      <td>topic</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-04-07 16:43:59</td>\n",
       "      <td>2023-04-07 16:46:13</td>\n",
       "      <td>2023-04-07 16:46:13</td>\n",
       "      <td>math</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2023-04-07</td>\n",
       "      <td>0 days 00:02:14</td>\n",
       "      <td>2.233333</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1132</td>\n",
       "      <td>2533</td>\n",
       "      <td>102</td>\n",
       "      <td>42</td>\n",
       "      <td>topic</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-04-07 16:46:14</td>\n",
       "      <td>2023-04-07 16:46:27</td>\n",
       "      <td>2023-04-07 16:46:27</td>\n",
       "      <td>math</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2023-04-07</td>\n",
       "      <td>0 days 00:00:13</td>\n",
       "      <td>0.216667</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50137</th>\n",
       "      <td>114742</td>\n",
       "      <td>955</td>\n",
       "      <td>647</td>\n",
       "      <td>42</td>\n",
       "      <td>topic</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-03-07 06:36:32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-03-07 06:36:32</td>\n",
       "      <td>math</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2025-03-07</td>\n",
       "      <td>0 days 00:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50138</th>\n",
       "      <td>114743</td>\n",
       "      <td>955</td>\n",
       "      <td>106</td>\n",
       "      <td>42</td>\n",
       "      <td>topic</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-03-07 06:37:49</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-03-07 06:37:49</td>\n",
       "      <td>math</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2025-03-07</td>\n",
       "      <td>0 days 00:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50139</th>\n",
       "      <td>114744</td>\n",
       "      <td>955</td>\n",
       "      <td>104</td>\n",
       "      <td>42</td>\n",
       "      <td>topic</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-03-07 06:37:50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-03-07 06:37:50</td>\n",
       "      <td>math</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2025-03-07</td>\n",
       "      <td>0 days 00:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50140</th>\n",
       "      <td>114745</td>\n",
       "      <td>955</td>\n",
       "      <td>108</td>\n",
       "      <td>42</td>\n",
       "      <td>topic</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-03-07 06:37:54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-03-07 06:37:54</td>\n",
       "      <td>math</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2025-03-07</td>\n",
       "      <td>0 days 00:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50141</th>\n",
       "      <td>114746</td>\n",
       "      <td>955</td>\n",
       "      <td>2945</td>\n",
       "      <td>42</td>\n",
       "      <td>quiz</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-03-07 06:42:09</td>\n",
       "      <td>2025-03-07 06:54:21</td>\n",
       "      <td>2025-03-07 06:54:21</td>\n",
       "      <td>math</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2025-03-07</td>\n",
       "      <td>0 days 00:12:12</td>\n",
       "      <td>12.200000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25938 rows × 16 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 176
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T14:39:29.748374Z",
     "start_time": "2025-04-17T14:39:26.668392Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Rolling window for recent activity\n",
    "rolling_window_days = 10\n",
    "\n",
    "# Convert the 'date' columns to datetime\n",
    "activity_math['activity_updated'] = pd.to_datetime(activity_math['activity_updated'])\n",
    "performances_math['time'] = pd.to_datetime(performances_math['time'])\n",
    "\n",
    "def compute_all_features_for_exam_no_time(exam_row, user_activities, user_exams, window_days=rolling_window_days):\n",
    "\n",
    "    exam_dt = exam_row['time']\n",
    "\n",
    "    # Include activities up to and including exam_date\n",
    "    previous_activities = user_activities[user_activities['activity_updated'] < exam_dt].copy()\n",
    "\n",
    "    # Rolling window (activities in the last N days, including exam day)\n",
    "    window_start = exam_dt - pd.Timedelta(days=window_days)\n",
    "    rolling_activities = previous_activities[previous_activities['activity_updated'] >= window_start].copy()\n",
    "\n",
    "    features = {}\n",
    "\n",
    "    # Recent average time per activity (rolling window)\n",
    "    #total_time_rolling = rolling_activities['time_in_minutes'].sum()\n",
    "    count_rolling = len(rolling_activities)\n",
    "    #features['recent_avg_time_per_activity'] = total_time_rolling / count_rolling if count_rolling > 0 else 0\n",
    "\n",
    "    # Number of days since last activity\n",
    "    if not previous_activities.empty:\n",
    "        last_activity_date = previous_activities['activity_updated'].max()\n",
    "        features['days_since_last_activity'] = (exam_dt - last_activity_date).days\n",
    "    else:\n",
    "        features['days_since_last_activity'] = np.nan\n",
    "\n",
    "    # Total time spent on activities before the exam\n",
    "    #features['total_time_spent_on_activity_before_exam'] = previous_activities['time_in_minutes'].sum() if not previous_activities.empty else 0\n",
    "\n",
    "    # Average percentage on past exams\n",
    "    previous_exams = user_exams[user_exams['time'] < exam_dt]\n",
    "    features['average_percentage_past_exams'] = previous_exams['percentage'].mean() if not previous_exams.empty else np.nan\n",
    "\n",
    "    # Usage Frequency: Average activities per day in rolling window & Active days ratio\n",
    "    features['avg_activities_per_day_recent'] = count_rolling / window_days if window_days > 0 else np.nan\n",
    "    if not rolling_activities.empty:\n",
    "        distinct_days = rolling_activities['activity_updated'].dt.normalize().nunique()\n",
    "    else:\n",
    "        distinct_days = 0\n",
    "    features['active_days_ratio_recent'] = distinct_days / window_days if window_days > 0 else np.nan\n",
    "\n",
    "    # Activity diversity (rolling window)\n",
    "    features['diversity_recent'] = rolling_activities['activity_type'].nunique() if not rolling_activities.empty else 0\n",
    "\n",
    "\n",
    "    return pd.Series(features)\n",
    "\n",
    "# Loop over each exam (grouped by user) in performances_math and compute all features.\n",
    "features_list = []\n",
    "\n",
    "for user_id, user_exams in performances_math.groupby('user_id'):\n",
    "    # Get corresponding activities for the user from activity_math and sort by date\n",
    "    user_activities = activity_math[activity_math['user_id'] == user_id].sort_values('activity_updated')\n",
    "    user_exams_sorted = user_exams.sort_values('time')\n",
    "\n",
    "    for exam_index, exam_row in user_exams_sorted.iterrows():\n",
    "        feats = compute_all_features_for_exam_no_time(exam_row, user_activities, user_exams_sorted, rolling_window_days)\n",
    "        feats['exam_index'] = exam_index\n",
    "        features_list.append(feats)\n",
    "\n",
    "# Output df\n",
    "features_df = pd.DataFrame(features_list).set_index('exam_index')\n",
    "performances_math_features = performances_math.join(features_df, how='left')"
   ],
   "id": "af18bda9a1342ebd",
   "outputs": [],
   "execution_count": 177
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T14:39:29.764284Z",
     "start_time": "2025-04-17T14:39:29.755637Z"
    }
   },
   "cell_type": "code",
   "source": "performances_math_features",
   "id": "7e694495d6fa7e12",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        user_id domain test_id  course        date                time  \\\n",
       "9.0           6   math      42    3865  2024-11-23 2024-11-23 10:25:34   \n",
       "10.0          6   math      48    3865  2025-01-08 2025-01-08 14:48:04   \n",
       "11.0          6   math      49    3865  2025-01-08 2025-01-08 15:29:07   \n",
       "12.0          6   math      50    3865  2025-02-04 2025-02-04 15:36:38   \n",
       "13.0          6   math      54    3865  2024-11-23 2024-11-23 11:26:10   \n",
       "...         ...    ...     ...     ...         ...                 ...   \n",
       "4826.0     4095   math      49    3865  2024-10-18 2024-10-18 15:41:47   \n",
       "4827.0     4095   math      50    3865  2024-10-18 2024-10-18 15:49:00   \n",
       "4828.0     4095   math      51    3865  2024-09-24 2024-09-24 16:00:51   \n",
       "4829.0     4095   math      53    3865  2024-09-24 2024-09-24 16:07:01   \n",
       "4830.0     4095   math      54    3865  2024-10-30 2024-10-30 16:59:44   \n",
       "\n",
       "        percentage  performance  days_since_last_activity  \\\n",
       "9.0          25.00       -36.04                       0.0   \n",
       "10.0         50.00        -1.92                       0.0   \n",
       "11.0         66.67        21.23                       0.0   \n",
       "12.0         54.55        19.57                       1.0   \n",
       "13.0         14.29       -47.71                       0.0   \n",
       "...            ...          ...                       ...   \n",
       "4826.0        0.00       -45.44                       0.0   \n",
       "4827.0        0.00       -34.98                       0.0   \n",
       "4828.0       20.00       -22.98                       0.0   \n",
       "4829.0        0.00       -56.46                       0.0   \n",
       "4830.0       28.57       -33.43                       0.0   \n",
       "\n",
       "        average_percentage_past_exams  avg_activities_per_day_recent  \\\n",
       "9.0                               NaN                            0.4   \n",
       "10.0                        29.822500                            0.6   \n",
       "11.0                        33.858000                            0.7   \n",
       "12.0                        39.326667                            1.2   \n",
       "13.0                        25.000000                            0.9   \n",
       "...                               ...                            ...   \n",
       "4826.0                      20.625000                            0.1   \n",
       "4827.0                      16.500000                            0.2   \n",
       "4828.0                            NaN                            0.4   \n",
       "4829.0                      20.000000                            0.5   \n",
       "4830.0                      24.285714                            0.7   \n",
       "\n",
       "        active_days_ratio_recent  diversity_recent  \n",
       "9.0                          0.2               2.0  \n",
       "10.0                         0.3               2.0  \n",
       "11.0                         0.3               2.0  \n",
       "12.0                         0.1               1.0  \n",
       "13.0                         0.2               3.0  \n",
       "...                          ...               ...  \n",
       "4826.0                       0.1               1.0  \n",
       "4827.0                       0.1               1.0  \n",
       "4828.0                       0.2               1.0  \n",
       "4829.0                       0.2               2.0  \n",
       "4830.0                       0.1               2.0  \n",
       "\n",
       "[3810 rows x 13 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>domain</th>\n",
       "      <th>test_id</th>\n",
       "      <th>course</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>percentage</th>\n",
       "      <th>performance</th>\n",
       "      <th>days_since_last_activity</th>\n",
       "      <th>average_percentage_past_exams</th>\n",
       "      <th>avg_activities_per_day_recent</th>\n",
       "      <th>active_days_ratio_recent</th>\n",
       "      <th>diversity_recent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9.0</th>\n",
       "      <td>6</td>\n",
       "      <td>math</td>\n",
       "      <td>42</td>\n",
       "      <td>3865</td>\n",
       "      <td>2024-11-23</td>\n",
       "      <td>2024-11-23 10:25:34</td>\n",
       "      <td>25.00</td>\n",
       "      <td>-36.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <td>6</td>\n",
       "      <td>math</td>\n",
       "      <td>48</td>\n",
       "      <td>3865</td>\n",
       "      <td>2025-01-08</td>\n",
       "      <td>2025-01-08 14:48:04</td>\n",
       "      <td>50.00</td>\n",
       "      <td>-1.92</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.822500</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11.0</th>\n",
       "      <td>6</td>\n",
       "      <td>math</td>\n",
       "      <td>49</td>\n",
       "      <td>3865</td>\n",
       "      <td>2025-01-08</td>\n",
       "      <td>2025-01-08 15:29:07</td>\n",
       "      <td>66.67</td>\n",
       "      <td>21.23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.858000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12.0</th>\n",
       "      <td>6</td>\n",
       "      <td>math</td>\n",
       "      <td>50</td>\n",
       "      <td>3865</td>\n",
       "      <td>2025-02-04</td>\n",
       "      <td>2025-02-04 15:36:38</td>\n",
       "      <td>54.55</td>\n",
       "      <td>19.57</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.326667</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13.0</th>\n",
       "      <td>6</td>\n",
       "      <td>math</td>\n",
       "      <td>54</td>\n",
       "      <td>3865</td>\n",
       "      <td>2024-11-23</td>\n",
       "      <td>2024-11-23 11:26:10</td>\n",
       "      <td>14.29</td>\n",
       "      <td>-47.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4826.0</th>\n",
       "      <td>4095</td>\n",
       "      <td>math</td>\n",
       "      <td>49</td>\n",
       "      <td>3865</td>\n",
       "      <td>2024-10-18</td>\n",
       "      <td>2024-10-18 15:41:47</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-45.44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.625000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4827.0</th>\n",
       "      <td>4095</td>\n",
       "      <td>math</td>\n",
       "      <td>50</td>\n",
       "      <td>3865</td>\n",
       "      <td>2024-10-18</td>\n",
       "      <td>2024-10-18 15:49:00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-34.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.500000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4828.0</th>\n",
       "      <td>4095</td>\n",
       "      <td>math</td>\n",
       "      <td>51</td>\n",
       "      <td>3865</td>\n",
       "      <td>2024-09-24</td>\n",
       "      <td>2024-09-24 16:00:51</td>\n",
       "      <td>20.00</td>\n",
       "      <td>-22.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4829.0</th>\n",
       "      <td>4095</td>\n",
       "      <td>math</td>\n",
       "      <td>53</td>\n",
       "      <td>3865</td>\n",
       "      <td>2024-09-24</td>\n",
       "      <td>2024-09-24 16:07:01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-56.46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4830.0</th>\n",
       "      <td>4095</td>\n",
       "      <td>math</td>\n",
       "      <td>54</td>\n",
       "      <td>3865</td>\n",
       "      <td>2024-10-30</td>\n",
       "      <td>2024-10-30 16:59:44</td>\n",
       "      <td>28.57</td>\n",
       "      <td>-33.43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.285714</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3810 rows × 13 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 178
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T14:39:29.826495Z",
     "start_time": "2025-04-17T14:39:29.821551Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# scaling the columns\n",
    "columns_to_scale = [ 'days_since_last_activity','average_percentage_past_exams','avg_activities_per_day_recent','active_days_ratio_recent','diversity_recent']\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_values = scaler.fit_transform(performances_math_features[columns_to_scale])\n",
    "scaled_df = pd.DataFrame(scaled_values, columns=columns_to_scale, index=performances_math_features.index)\n",
    "remaining_df = performances_math_features.drop(columns=columns_to_scale)\n",
    "final_df = pd.concat([scaled_df, remaining_df], axis=1)"
   ],
   "id": "8d4180885034dfa1",
   "outputs": [],
   "execution_count": 179
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T14:39:51.462431Z",
     "start_time": "2025-04-17T14:39:51.440836Z"
    }
   },
   "cell_type": "code",
   "source": "final_df.dropna(inplace=True)",
   "id": "85cbd1959b464068",
   "outputs": [],
   "execution_count": 180
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T14:40:15.212651Z",
     "start_time": "2025-04-17T14:40:15.172041Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# Linear Regression Model\n",
    "mod = smf.ols(\n",
    "    formula='performance ~  days_since_last_activity + average_percentage_past_exams + avg_activities_per_day_recent + active_days_ratio_recent + diversity_recent',\n",
    "    data=final_df)\n",
    "\n",
    "# Fit the model\n",
    "res = mod.fit()\n",
    "\n",
    "# Print regression results summary\n",
    "print(res.summary())"
   ],
   "id": "1372a3ad1a833771",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:            performance   R-squared:                       0.217\n",
      "Model:                            OLS   Adj. R-squared:                  0.216\n",
      "Method:                 Least Squares   F-statistic:                     184.6\n",
      "Date:                Thu, 17 Apr 2025   Prob (F-statistic):          6.47e-174\n",
      "Time:                        16:40:15   Log-Likelihood:                -15537.\n",
      "No. Observations:                3341   AIC:                         3.109e+04\n",
      "Df Residuals:                    3335   BIC:                         3.112e+04\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=================================================================================================\n",
      "                                    coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------------\n",
      "Intercept                         0.2884      0.440      0.656      0.512      -0.573       1.150\n",
      "days_since_last_activity          1.3418      0.560      2.394      0.017       0.243       2.441\n",
      "average_percentage_past_exams    12.6656      0.449     28.193      0.000      11.785      13.546\n",
      "avg_activities_per_day_recent    -2.5584      0.546     -4.686      0.000      -3.629      -1.488\n",
      "active_days_ratio_recent          1.9716      0.568      3.469      0.001       0.857       3.086\n",
      "diversity_recent                  0.4623      0.620      0.745      0.456      -0.754       1.679\n",
      "==============================================================================\n",
      "Omnibus:                       34.347   Durbin-Watson:                   1.560\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               24.303\n",
      "Skew:                          -0.091   Prob(JB):                     5.28e-06\n",
      "Kurtosis:                       2.624   Cond. No.                         2.61\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "execution_count": 182
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "1b40b8a861a72353"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
